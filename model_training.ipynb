{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQYfIcC7PrgxRv5IFXyESo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abbas-Muneer/Olympians/blob/DataScience/model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CifLc2FuGXqL",
        "outputId": "c04090cb-6576-4d5c-e317-c0afbcf065ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.7.0 in /usr/local/lib/python3.8/dist-packages (2.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (2.11.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.22.4)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (4.5.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.51.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (3.19.6)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (15.0.6.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (0.30.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (2.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (0.38.4)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (2.0.7)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (0.4.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.16.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2,preprocess_input\n",
        "from tensorflow.keras.layers import Dense,Conv2D,GlobalAveragePooling2D,Input\n",
        "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
        "from tensorflow.keras import callbacks,optimizers\n",
        "import numpy as np\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "RXpk91wlLfdg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJh2DAOyLrpb",
        "outputId": "41017e6a-2990-4b29-98fd-eb6bffa3bfb8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/model_training/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py3MMwjjL9QX",
        "outputId": "af89f9f7-3788-468c-87c0-5049664ae76b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/model_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir(\"content\"):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Idvovh5OMQJi",
        "outputId": "38e05aa0-35bc-4490-c6d6-8b9aa924e2d7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resnet-model-23-02-21.h5\n",
            "resnet_model_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls raw-img/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUNsPYtiNi5F",
        "outputId": "151027c3-c7d0-4959-96ef-c66d194c6355"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ACNE\t\t     Basal_Cell_Carcinoma   Melanocytic_Nevi   Psoriasis\n",
            " Atopic_Dermatitis   Eczema\t\t    Melanoma\t      'Skin Cancer'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir(\"raw-img\"):\n",
        "  print(i,len(os.listdir(\"raw-img/\" + i)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbLP51nrNx3S",
        "outputId": "a5899613-8859-4636-9494-ea10bf60fef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACNE 375\n",
            "Skin Cancer 3543\n",
            "Psoriasis 341\n",
            "Basal_Cell_Carcinoma 1323\n",
            "Melanocytic_Nevi 2020\n",
            "Atopic_Dermatitis 481\n",
            "Melanoma 1140\n",
            "Eczema 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir(\"train\")\n",
        "  os.mkdir(\"test\")\n",
        "except:\n",
        "  pass  \n",
        "for i in os.listdir(\"raw-img\"):\n",
        "  try:\n",
        "    os.mkdir(\"train/\" + i)\n",
        "    os.mkdir(\"test/\" + i)\n",
        "  except:\n",
        "    pass  \n",
        "  for j in os.listdir(\"raw-img/\" + i)[:1600]:\n",
        "    os.rename(\"raw-img/\"+i+\"/\"+j, \"train/\"+i+\"/\"+j)\n",
        "  for j in os.listdir(\"raw-img/\" + i)[:400]:\n",
        "    os.rename(\"raw-img/\"+i+\"/\"+j, \"test/\"+i+\"/\"+j)"
      ],
      "metadata": {
        "id": "fflKeaDdO0x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir(\"train\"):\n",
        "  print(i,len(os.listdir(\"train/\" + i)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDjBs81QojP7",
        "outputId": "7d889428-6227-4590-b960-58692830ff3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACNE 1600\n",
            "Psoriasis 1600\n",
            "Basal_Cell_Carcinoma 1600\n",
            "Melanocytic_Nevi 1600\n",
            "Atopic_Dermatitis 1600\n",
            "Melanoma 1600\n",
            "Eczema 1600\n",
            "Skin_Cancer 1600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def img_Data(dir_path,target_size,batch,class_lst,preporcssing):\n",
        "  if preporcssing:\n",
        "    gen_object = ImageDataGenerator(preprocessing_function=preporcssing)\n",
        "  else:\n",
        "    gen_object = ImageDataGenerator()\n",
        "\n",
        "  return(gen_object.flow_from_directory(dir_path,\n",
        "                                        target_size=target_size,\n",
        "                                        batch_size=batch,\n",
        "                                        class_mode='sparse',\n",
        "                                        classes = class_lst,\n",
        "                                        shuffle=True))"
      ],
      "metadata": {
        "id": "edx_MdMcUJ1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen = img_Data(\"train\",(224,224),500,os.listdir(\"train\"),preprocess_input)\n",
        "valid_data_gen = img_Data(\"test\",(224,224),500,os.listdir(\"test\"),preprocess_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBCrSwINsHxN",
        "outputId": "4b9e6cfb-c4b7-4875-d10f-768286b7261b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12799 images belonging to 8 classes.\n",
            "Found 3200 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2( input_shape=(224,224,3),\n",
        "                                                             alpha=1.0,\n",
        "                                                             include_top=False,\n",
        "                                                             weights='imagenet',\n",
        "                                                             input_tensor=None,\n",
        "                                                             pooling=None,\n",
        "                                                             classes=1000,\n",
        "                                                             classifier_activation='softmax')\n",
        "                                        \n",
        "   \n"
      ],
      "metadata": {
        "id": "SkVlu-wmtiLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "ZxKzXARIuSAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(1024,activation='relu'))\n",
        "model.add(Dense(8,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "              "
      ],
      "metadata": {
        "id": "b-k2VxGYuvKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elst = callbacks.EarlyStopping(monitor='val_loss',patience=5,mode='min')\n",
        "save_ck = callbacks.ModelCheckpoint(' .mdl_wt.hdf5',save_best_only=True,monitor='val_loss',mode= 'min')"
      ],
      "metadata": {
        "id": "Q1mx_AZ4w49A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data_gen,batch_size=500,validation_data=valid_data_gen,callbacks=[elst,save_ck],epochs=10)"
      ],
      "metadata": {
        "id": "emqOf7IOx2ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#retrying model training with resnet model instead of mobileNetV2 model\n",
        "!pip install tensorflow keras-tuner opencv-python matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5oLkEZQCPwn",
        "outputId": "8a4058ff-8125-418a-db62-423bd935545b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.8/dist-packages (1.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.5.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1.21)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.30.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.38.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.18.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.14.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "xM77YuaNC5NL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_TRAINING_PATH = 'train'\n",
        "BATCH_SIZE = 32\n",
        "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
        "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "\n",
        "DATA_TESTING_PATH = 'test'\n",
        "BATCH_SIZE = 32\n",
        "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
        "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH, 3)"
      ],
      "metadata": {
        "id": "yrPg9mg8C98I"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_TRAINING_PATH,\n",
        "    label_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    validation_split=0.0001,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "val_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_TESTING_PATH,\n",
        "    label_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    validation_split=0.9999,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    shuffle=False,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKllVlUFDZNe",
        "outputId": "d95bb436-7878-4130-9581-caed7e6b5593"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12799 files belonging to 8 classes.\n",
            "Using 12798 files for training.\n",
            "Found 3200 files belonging to 8 classes.\n",
            "Using 3199 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.class_names\n",
        "\n",
        "# optimize\n",
        "train_data = train_data.prefetch(tf.data.AUTOTUNE)\n",
        "val_data = val_data.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "cSyGDoVOD_c9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.applications import ResNet50V2, VGG19, InceptionV3"
      ],
      "metadata": {
        "id": "A_NnyJo_ExI2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50V2(\n",
        "    include_top=False, # Exclude ImageNet classifier at the top\n",
        "    weights='imagenet',\n",
        "    input_shape=IMG_SIZE\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTVeAHe_E0C0",
        "outputId": "81e8423f-c67b-419d-e12e-76c4a202136a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomTranslation, RandomContrast"
      ],
      "metadata": {
        "id": "xEd9g02lE88A"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [RandomFlip('horizontal'), \n",
        "     RandomRotation(factor=(-0.025, 0.025)),\n",
        "     RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "     RandomContrast(factor=0.1)\n",
        "     ])\n",
        "\n",
        "\n",
        "\n",
        "# Create new model on top\n",
        "inputs = keras.Input(shape=IMG_SIZE)\n",
        "x = data_augmentation(inputs)\n",
        "\n",
        "x = keras.applications.resnet_v2.preprocess_input(x)\n",
        "x = base_model(x, training=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwyofLUqE_ln",
        "outputId": "feb7dab4-3639-44a6-fbaa-763b3313f783"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization, Dropout, Flatten, Dense"
      ],
      "metadata": {
        "id": "VOrSD0ZjFE-Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)  # Regularize with dropout\n",
        "\n",
        "outputs = Dense(len(class_names), activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "resnet_model = keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "\n",
        "resnet_model.summary()"
      ],
      "metadata": {
        "id": "zq6yGgYBFHwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy"
      ],
      "metadata": {
        "id": "fYr5PLGsFNH7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [CategoricalAccuracy(), Precision(), Recall()]\n",
        "\n",
        "resnet_model.compile(\n",
        "    loss = CategoricalCrossentropy(),\n",
        "    optimizer = Adam(learning_rate=0.001),\n",
        "    metrics = metrics\n",
        "    )\n",
        "\n",
        "es = EarlyStopping(patience=6, monitor='val_loss', mode='min', restore_best_weights=True)\n",
        "\n",
        "\n",
        "\n",
        "resnet_history = resnet_model.fit(\n",
        "      train_data, \n",
        "      epochs=25, \n",
        "      validation_data=val_data,\n",
        "      callbacks=[es],\n",
        "      verbose=1\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "resnet_model.save('resnet-model-23-02-21.h5')\n",
        "\n",
        "\n",
        "\n",
        "result = resnet_model.evaluate(val_data)\n",
        "result\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jF2JeJEcFT4m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c54ea3-cf1a-4869-d6f2-597055d6ec7f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400/400 [==============================] - 3572s 9s/step - loss: 1.0890 - categorical_accuracy: 0.6018 - precision: 0.6684 - recall: 0.5177 - val_loss: 0.9819 - val_categorical_accuracy: 0.6118 - val_precision: 0.6681 - val_recall: 0.5192\n",
            "Epoch 2/25\n",
            "400/400 [==============================] - 221s 549ms/step - loss: 0.8595 - categorical_accuracy: 0.6702 - precision: 0.7213 - recall: 0.6067 - val_loss: 0.9612 - val_categorical_accuracy: 0.6274 - val_precision: 0.6761 - val_recall: 0.5671\n",
            "Epoch 3/25\n",
            "400/400 [==============================] - 224s 557ms/step - loss: 0.7844 - categorical_accuracy: 0.6893 - precision: 0.7363 - recall: 0.6341 - val_loss: 0.9753 - val_categorical_accuracy: 0.6327 - val_precision: 0.6726 - val_recall: 0.5824\n",
            "Epoch 4/25\n",
            "400/400 [==============================] - 217s 540ms/step - loss: 0.7552 - categorical_accuracy: 0.7011 - precision: 0.7480 - recall: 0.6502 - val_loss: 0.9680 - val_categorical_accuracy: 0.6286 - val_precision: 0.6703 - val_recall: 0.5789\n",
            "Epoch 5/25\n",
            "400/400 [==============================] - 222s 553ms/step - loss: 0.7366 - categorical_accuracy: 0.7077 - precision: 0.7481 - recall: 0.6578 - val_loss: 0.9417 - val_categorical_accuracy: 0.6386 - val_precision: 0.6799 - val_recall: 0.5824\n",
            "Epoch 6/25\n",
            "400/400 [==============================] - 219s 545ms/step - loss: 0.7241 - categorical_accuracy: 0.7129 - precision: 0.7535 - recall: 0.6642 - val_loss: 0.9780 - val_categorical_accuracy: 0.6368 - val_precision: 0.6706 - val_recall: 0.5867\n",
            "Epoch 7/25\n",
            "400/400 [==============================] - 220s 547ms/step - loss: 0.7129 - categorical_accuracy: 0.7145 - precision: 0.7556 - recall: 0.6691 - val_loss: 0.9775 - val_categorical_accuracy: 0.6268 - val_precision: 0.6625 - val_recall: 0.5780\n",
            "Epoch 8/25\n",
            "400/400 [==============================] - 217s 539ms/step - loss: 0.7120 - categorical_accuracy: 0.7127 - precision: 0.7540 - recall: 0.6672 - val_loss: 0.9486 - val_categorical_accuracy: 0.6343 - val_precision: 0.6717 - val_recall: 0.5833\n",
            "Epoch 9/25\n",
            "400/400 [==============================] - 215s 535ms/step - loss: 0.7047 - categorical_accuracy: 0.7199 - precision: 0.7574 - recall: 0.6752 - val_loss: 0.9545 - val_categorical_accuracy: 0.6408 - val_precision: 0.6730 - val_recall: 0.5861\n",
            "Epoch 10/25\n",
            "400/400 [==============================] - 217s 537ms/step - loss: 0.7081 - categorical_accuracy: 0.7175 - precision: 0.7563 - recall: 0.6764 - val_loss: 0.9416 - val_categorical_accuracy: 0.6430 - val_precision: 0.6820 - val_recall: 0.5980\n",
            "Epoch 11/25\n",
            "400/400 [==============================] - 217s 540ms/step - loss: 0.7034 - categorical_accuracy: 0.7184 - precision: 0.7563 - recall: 0.6778 - val_loss: 0.9354 - val_categorical_accuracy: 0.6386 - val_precision: 0.6697 - val_recall: 0.6002\n",
            "Epoch 12/25\n",
            "400/400 [==============================] - 215s 535ms/step - loss: 0.6998 - categorical_accuracy: 0.7175 - precision: 0.7575 - recall: 0.6767 - val_loss: 0.9292 - val_categorical_accuracy: 0.6330 - val_precision: 0.6732 - val_recall: 0.5930\n",
            "Epoch 13/25\n",
            "400/400 [==============================] - 213s 529ms/step - loss: 0.6946 - categorical_accuracy: 0.7226 - precision: 0.7572 - recall: 0.6827 - val_loss: 0.9409 - val_categorical_accuracy: 0.6405 - val_precision: 0.6772 - val_recall: 0.5936\n",
            "Epoch 14/25\n",
            "400/400 [==============================] - 214s 533ms/step - loss: 0.6831 - categorical_accuracy: 0.7253 - precision: 0.7625 - recall: 0.6829 - val_loss: 0.9941 - val_categorical_accuracy: 0.6377 - val_precision: 0.6689 - val_recall: 0.5999\n",
            "Epoch 15/25\n",
            "400/400 [==============================] - 218s 542ms/step - loss: 0.6907 - categorical_accuracy: 0.7217 - precision: 0.7569 - recall: 0.6788 - val_loss: 0.9423 - val_categorical_accuracy: 0.6458 - val_precision: 0.6846 - val_recall: 0.6039\n",
            "Epoch 16/25\n",
            "400/400 [==============================] - 221s 550ms/step - loss: 0.6791 - categorical_accuracy: 0.7273 - precision: 0.7600 - recall: 0.6843 - val_loss: 0.9326 - val_categorical_accuracy: 0.6461 - val_precision: 0.6840 - val_recall: 0.6014\n",
            "Epoch 17/25\n",
            "400/400 [==============================] - 215s 535ms/step - loss: 0.6827 - categorical_accuracy: 0.7239 - precision: 0.7626 - recall: 0.6851 - val_loss: 0.9779 - val_categorical_accuracy: 0.6389 - val_precision: 0.6716 - val_recall: 0.5971\n",
            "Epoch 18/25\n",
            "400/400 [==============================] - 217s 539ms/step - loss: 0.6861 - categorical_accuracy: 0.7217 - precision: 0.7574 - recall: 0.6795 - val_loss: 0.9297 - val_categorical_accuracy: 0.6458 - val_precision: 0.6837 - val_recall: 0.6068\n",
            "100/100 [==============================] - 19s 184ms/step - loss: 0.9292 - categorical_accuracy: 0.6330 - precision: 0.6732 - recall: 0.5930\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.929154634475708, 0.6330103278160095, 0.6731724739074707, 0.5929977893829346]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls content/resnet_model_training\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ex3oYFtttvd",
        "outputId": "75c0ecae-cc6c-4deb-a934-0d80af1ce16a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abbas1.jpg  ACNE.png  Atomic.jpg  psoriasis.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "infection_CLASSES = {x:y for x,y in enumerate(class_names)}\n",
        "MODEL_DIR = 'My Drive/model_training/content/resnet-model-23-02-21.h5'\n",
        "MODEL = keras.models.load_model('content/resnet-model-23-02-21.h5')\n",
        "\n",
        "def predict_image_class(img_path:str) -> str:\n",
        "  img = keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n",
        "  img_array = keras.preprocessing.image.img_to_array(img)\n",
        "  img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "  predictions = MODEL.predict(img_array)\n",
        "\n",
        "  return infection_CLASSES[predictions.argmax(axis=1)[0]]\n",
        "\n",
        "\n",
        "\n",
        "TEST_IMG_DIR = \"content/resnet_model_training/psoriasis.jpg\"\n",
        "print(f\"Prediction - {predict_image_class(TEST_IMG_DIR)}\")\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.download('content/resnet-model-23-02-21.h5')"
      ],
      "metadata": {
        "id": "ZZLcizjns6fE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}